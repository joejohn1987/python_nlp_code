{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf\n",
    "\n",
    "Tf-idf, short for term frequencyâ€“inverse document frequency, is a method to summerize a text by its word frequecy  weighted with inverse document frequency. The theory behind is if a word happens more in a text is more important than the other words, and a word happens in more document is less significant.\n",
    "\n",
    "$tfidf_{i,d} = tf_{i,d} \\cdot idf_{i}$ where<br>\n",
    "$idf( t, D ) = log \\frac{ \\text{| } D \\text{ |} }{ 1 + \\text{| } \\{ d \\in D : t \\in d \\} \\text{ |} }$\n",
    "<br>Read more on https://en.wikipedia.org/wiki/Tf%E2%80%93idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a small corpus before impletementing the tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this', 'is', 'a', 'girl', 'with', 'a', 'telescope', '.'], ['this', 'is', 'a', 'boy', 'with', 'a', 'pizza', '.'], ['irrelevent', 'sentence', 'should', 'tell', 'a', 'difference', '!']]\n"
     ]
    }
   ],
   "source": [
    "# read file line by line and \n",
    "texts = ['This is a girl with a telescope .',\n",
    "        'This is a boy with a pizza .',\n",
    "         'Irrelevent sentence should tell a difference !']\n",
    "def tokenizer(texts):\n",
    "    tokenized_texts = []\n",
    "    for text in texts:\n",
    "        tokenized_texts.append(text.lower().split())\n",
    "    return tokenized_texts\n",
    "    \n",
    "tokenized_texts = tokenizer(texts)\n",
    "print(tokenized_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we count the document frequency for all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 3, 'this': 2, 'with': 2, '.': 2, 'is': 2, 'girl': 1, 'telescope': 1, 'pizza': 1, 'boy': 1, 'should': 1, 'tell': 1, 'irrelevent': 1, '!': 1, 'difference': 1, 'sentence': 1}\n"
     ]
    }
   ],
   "source": [
    "def df_count(tokenized_texts):\n",
    "    df = {}\n",
    "    # Let's count the words\n",
    "    for doc in tokenized_texts:\n",
    "        word_type = set(doc)\n",
    "        for word in word_type:\n",
    "            try:\n",
    "                df[word] += 1\n",
    "            except:\n",
    "                df[word] = 1\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = df_count(tokenized_texts)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make a function to get the term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 0.125, 'is': 0.125, 'a': 0.25, 'girl': 0.125, 'with': 0.125, 'telescope': 0.125, '.': 0.125}\n"
     ]
    }
   ],
   "source": [
    "#function for only one documents\n",
    "def tf_count(tokenized_text):\n",
    "    tf = {}\n",
    "    total_no = len(tokenized_text)\n",
    "    for token in tokenized_text:\n",
    "            try:\n",
    "                tf[token] += 1\n",
    "            except:\n",
    "                tf[token] = 1\n",
    "    for key in tf.keys():\n",
    "        tf[key] = tf[key]/total_no\n",
    "    return tf\n",
    "\n",
    "print(tf_count(tokenized_texts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can calculate the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0, 0.022011407381960155, 0.022011407381960155, 0.022011407381960155, 0.022011407381960155, 0.059640156839957804, 0.059640156839957804, 0, 0, 0, 0, 0, 0, 0, 0], [0.0, 0.022011407381960155, 0.022011407381960155, 0.022011407381960155, 0.022011407381960155, 0, 0, 0.059640156839957804, 0.059640156839957804, 0, 0, 0, 0, 0, 0], [0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0.06816017924566606, 0.06816017924566606, 0.06816017924566606, 0.06816017924566606, 0.06816017924566606, 0.06816017924566606]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def get_score(tokenized_texts):\n",
    "    tfidf = []\n",
    "    df = df_count(tokenized_texts)\n",
    "    total_docs = len(tokenized_texts)\n",
    "    for doc in tokenized_texts:\n",
    "        tf = tf_count(doc)\n",
    "        score = []\n",
    "        for word in df.keys():\n",
    "            try:\n",
    "                score.append(tf[word]*(math.log10(total_docs/df[word])))\n",
    "            except:\n",
    "                score.append(0)\n",
    "        tfidf.append(score)\n",
    "    return tfidf\n",
    "tf_idf = get_score(tokenized_texts)\n",
    "print(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have document vectors, how can we make use of them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity\n",
    "\n",
    "Cosine similarity measures the orientation of two n-dimensional sample vectors irrespective to their magnitude.\n",
    "It is very common to use td-idf with cosine similartiy.<br>\n",
    "$\\cos(\\pmb x, \\pmb y) = \\frac {\\pmb x \\cdot \\pmb y}{||\\pmb x|| \\cdot ||\\pmb y||}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def cosSim(A,B):\n",
    "    #compute cosine similarity of A to B: (A dot B)/{||A||*||B||)\n",
    "    sum_aa, sum_ab, sum_bb = 0, 0, 0\n",
    "    for i in range(len(A)):\n",
    "        a = A[i]; b = B[i]\n",
    "        sum_aa += a*a\n",
    "        sum_ab += a*b\n",
    "        sum_bb += b*b\n",
    "    return sum_ab/math.sqrt(sum_aa*sum_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between 1st doc and 2nd doc: 0.21409949120674793\n",
      "similarity between 1st doc and 3nd doc: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sim_score = cosSim(tf_idf[0],tf_idf[1])\n",
    "print('similarity between 1st doc and 2nd doc:', sim_score)\n",
    "sim_score = cosSim(tf_idf[0],tf_idf[2])\n",
    "print('similarity between 1st doc and 3nd doc:',sim_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that doc 1 and 2 is more similar to each other than to doc3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
