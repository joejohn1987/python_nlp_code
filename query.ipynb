{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple search engine\n",
    "\n",
    "Let's say we want to search every document contains 'apple', how should we do? In this script \n",
    "\n",
    "First we have to tokenized the text file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have no problem with this, Anderson did not deserve to hang around for a win\n",
      "['i', 'have', 'no', 'problem', 'with', 'this,', 'anderson', 'did', 'not', 'deserve', 'to', 'hang', 'around', 'for', 'a', 'win']\n"
     ]
    }
   ],
   "source": [
    "# read file line by line and \n",
    "def readfile(path):\n",
    "    raw_text = []\n",
    "    tokenized_text = []\n",
    "    with open(path, 'r') as f:\n",
    "        lines =  f.readlines()\n",
    "        for line in lines:\n",
    "            text = line.strip().split('\\t')[-1]\n",
    "            raw_text.append(text)\n",
    "            tokens = text.split()\n",
    "            for i in range(len(tokens)):\n",
    "                tokens[i] = tokens[i].lower()\n",
    "            tokenized_text.append(tokens)\n",
    "    return raw_text, tokenized_text\n",
    "raw_text, tokenized_text = readfile('data/tweets_10k')\n",
    "# print the first document\n",
    "print(raw_text[0])\n",
    "print(tokenized_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way is to search document by document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[228, 1428, 1935, 2401, 3221, 3688, 7212, 8420, 8604, 9201, 9749, 9997]\n",
      "Decifrando o convite do evento Apple ![NEWLINE]#Me #tbt #photooftheday #apple #nissan #pokemon #abreusnett #olympics... https://t.co/vEW0x9zW8D\n"
     ]
    }
   ],
   "source": [
    "def search_line_by_line(tokenized_text, query_word):\n",
    "    result = []\n",
    "    for i in range(len(tokenized_text)):\n",
    "        if query_word in tokenized_text[i]:\n",
    "            result.append(i)\n",
    "    if len(result) == 0:\n",
    "        print('No document can be found.')\n",
    "    return result\n",
    "    \n",
    "query_word = 'apple'\n",
    "doc_id = search_line_by_line(tokenized_text, query_word)\n",
    "print(doc_id)\n",
    "print(raw_text[doc_id[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is very troublesome if the data set is huge, and you have to repeat the searching process everytime.\n",
    "Another method is to build an inverted index in advanced.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inverted index\n",
    "\n",
    "The idea is simple, we build a dictionary contains every word type and its relevant doc id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_index(tokenized_text): \n",
    "    inverted_index = {}\n",
    "    doc_no = 0\n",
    "    vocabulary = set()\n",
    "    for i in range(len(tokenized_text)):\n",
    "        for token in tokenized_text[i]:\n",
    "            if token in inverted_index.keys():\n",
    "                try:\n",
    "                    inverted_index[token][doc_no] += 1\n",
    "                except:\n",
    "                    inverted_index[token][doc_no] = 1\n",
    "            else:\n",
    "                inverted_index[token] = {}\n",
    "                inverted_index[token][doc_no] = 1\n",
    "        \n",
    "        #counting the lines\n",
    "        doc_no += 1\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('problem', {0: 1, 69: 1, 269: 1, 278: 1, 362: 1, 693: 1, 816: 1, 1200: 1, 1230: 1, 1614: 1, 2122: 1, 2128: 1, 2204: 1, 3007: 1, 3079: 1, 3292: 1, 3362: 1, 3633: 1, 4249: 1, 4343: 1, 4345: 1, 4734: 1, 5189: 1, 5354: 1, 5619: 1, 5688: 1, 6339: 1, 6435: 1, 6521: 1, 6609: 1, 6673: 1, 7052: 1, 7063: 1, 7084: 1, 7185: 1, 7319: 1, 7540: 1, 7796: 1, 7865: 1, 8177: 1, 8647: 1, 8895: 1, 9034: 1, 9147: 1, 9420: 1, 9538: 1, 9847: 1, 9913: 1, 9987: 1})\n"
     ]
    }
   ],
   "source": [
    "# try to build the index\n",
    "inverted_index = build_index(tokenized_text)\n",
    "# print an item to see the result\n",
    "print(list(inverted_index.items())[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now we can search by inverted index\n",
    "def search_by_index(inverted_index, query_word):\n",
    "    try:\n",
    "        return list(inverted_index[query_word].keys())\n",
    "    except:\n",
    "        print('No result')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n",
      "Decifrando o convite do evento Apple ![NEWLINE]#Me #tbt #photooftheday #apple #nissan #pokemon #abreusnett #olympics... https://t.co/vEW0x9zW8D\n"
     ]
    }
   ],
   "source": [
    "query_word = 'apple'\n",
    "result = search_by_index(inverted_index, query_word )\n",
    "print(result[0])\n",
    "print(raw_text[result[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can modify it to search with more than one word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_more_words(inverted_index, query_words):\n",
    "    all_results = []\n",
    "    for word in query_words:\n",
    "        try:\n",
    "            all_results.append(list(inverted_index[word].keys()))\n",
    "        except:\n",
    "            print('No result for ' + word)\n",
    "            return []\n",
    "    common_result = set(all_results[0])\n",
    "    for i in range(1,len(all_results)):\n",
    "        common_result = common_result.intersection(all_results[i])\n",
    "    if len(common_result)==0:\n",
    "        print('No document contains all word.')\n",
    "    return common_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{9201}\n"
     ]
    }
   ],
   "source": [
    "query_word = ['apple','i']\n",
    "result = search_more_words(inverted_index, query_word )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'set' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-0ee3280229cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object does not support indexing"
     ]
    }
   ],
   "source": [
    "print(raw_text[result[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
